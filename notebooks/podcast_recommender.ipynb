{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_df = pd.read_pickle('../pickle_files/english_podcasts_detailed_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_df['text'] = podcasts_df[['title', 'producer', 'genre', 'description', 'episode_titles', 'episode_descriptions']].apply(lambda x: ' '.join(x), axis=1)\n",
    "podcasts_df = podcasts_df.drop(columns=['genre', 'description', 'num_episodes', 'rating', 'num_reviews', 'link', 'episode_titles', 'episode_descriptions'])\n",
    "podcasts_df['ID'] = list(range(podcasts_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of stop words\n",
    "stop = get_stop_words('en')\n",
    "\n",
    "# remove non-alphanumeric, non-space\n",
    "stop = [re.sub(r'([^\\s\\w]|_)+', '', x) for x in stop]\n",
    "\n",
    "# add in custom stop words\n",
    "days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', \n",
    "          'july', 'august', 'september', 'october', 'november', 'december']\n",
    "\n",
    "other = ['nan', 'podcast', 'podcasts', 'every', 'new', 'weekly', \n",
    "         'stories', 'story', 'episode', 'episodes', 'listen', \n",
    "         'host', 'hosted', 'join']\n",
    "\n",
    "[stop.append(str(day)) for day in days]\n",
    "[stop.append(str(month)) for month in months]\n",
    "[stop.append(str(x)) for x in other]\n",
    "\n",
    "def topKFrequent(tokenized_text, k): \n",
    "   \n",
    "    count = Counter(tokenized_text)   \n",
    "    \n",
    "    return heapq.nlargest(k, count.keys(), key=count.get)\n",
    "\n",
    "def remove_stop(text, stop):\n",
    "    custom_stop = stop\n",
    "#     top5 = topKFrequent(text, 5)\n",
    "#     custom_stop = custom_stop + top5\n",
    "    \n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word not in custom_stop:\n",
    "            new_text.append(word)\n",
    "    return new_text\n",
    "\n",
    "# create tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create stemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "l_stemmer = WordNetLemmatizer() \n",
    "\n",
    "\n",
    "def stem_list(text, p_stemmer):\n",
    "    new_list = []\n",
    "    for word in text:\n",
    "        new_list.append(p_stemmer.stem(word))\n",
    "    return new_list\n",
    "\n",
    "def lem_list(text, l_stemmer):\n",
    "    new_list = []\n",
    "    for word in text:\n",
    "        new_list.append(l_stemmer.lemmatize(word))\n",
    "    return new_list\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove mixed alphanumeric\n",
    "    text = re.sub(r\"\"\"(?x) # verbose regex\n",
    "                            \\b    # Start of word\n",
    "                            (?=   # Look ahead to ensure that this word contains...\n",
    "                             \\w*  # (after any number of alphanumeric characters)\n",
    "                             \\d   # ...at least one digit.\n",
    "                            )     # End of lookahead\n",
    "                            \\w+   # Match the alphanumeric word\n",
    "                            \\s*   # Match any following whitespace\"\"\", \n",
    "                             \"\", text)\n",
    "    \n",
    "    # remove urls (will check and remove http and www later)\n",
    "    text = re.sub(r'\\s([\\S]*.com[\\S]*)\\b', '', text)\n",
    "    text = re.sub(r'\\s([\\S]*.org[\\S]*)\\b', '', text)\n",
    "    text = re.sub(r'\\s([\\S]*.net[\\S]*)\\b', '', text)\n",
    "    text = re.sub(r'\\s([\\S]*.edu[\\S]*)\\b', '', text)\n",
    "    text = re.sub(r'\\s([\\S]*.gov[\\S]*)\\b', '', text)\n",
    "    \n",
    "    # remove non-alphanumeric, non-space\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    \n",
    "    # tokenize text\n",
    "    text = tokenizer.tokenize(text.lower())\n",
    "    \n",
    "    # remove stop words\n",
    "    text = remove_stop(text, stop)\n",
    "    \n",
    "    # stem\n",
    "    text = lem_list(text, l_stemmer)\n",
    "    \n",
    "    # remove instances of http or www\n",
    "    new_text_list = []\n",
    "    for word in text:\n",
    "        if re.search(r'http', word):\n",
    "            continue\n",
    "        if re.search(r'www', word):\n",
    "            continue\n",
    "        new_text_list.append(word)\n",
    "    \n",
    "    new_text = ' '.join(new_text_list)\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_df['text'] = podcasts_df['text'].map(preprocess_text)\n",
    "podcasts_df = podcasts_df[podcasts_df.text != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>producer</th>\n",
       "      <th>text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>History Hyenas with Chris Distefano and Yannis...</td>\n",
       "      <td>RiotCast Network</td>\n",
       "      <td>history hyena chris distefano yannis pappa rio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curiosity Daily</td>\n",
       "      <td>Westwood One</td>\n",
       "      <td>curiosity daily westwood one education awardwi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spirits</td>\n",
       "      <td>Multitude</td>\n",
       "      <td>spirit multitude history boozy mythology legen...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Soundtrack Show</td>\n",
       "      <td>iHeartRadio</td>\n",
       "      <td>soundtrack show iheartradio tv film soundtrack...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Writing Excuses</td>\n",
       "      <td>Brandon Sanderson, Mary Robinette Kowal, Dan W...</td>\n",
       "      <td>writing excuse brandon sanderson mary kowal da...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  History Hyenas with Chris Distefano and Yannis...   \n",
       "1                                    Curiosity Daily   \n",
       "2                                            Spirits   \n",
       "3                                The Soundtrack Show   \n",
       "4                                    Writing Excuses   \n",
       "\n",
       "                                            producer  \\\n",
       "0                                   RiotCast Network   \n",
       "1                                       Westwood One   \n",
       "2                                          Multitude   \n",
       "3                                        iHeartRadio   \n",
       "4  Brandon Sanderson, Mary Robinette Kowal, Dan W...   \n",
       "\n",
       "                                                text  ID  \n",
       "0  history hyena chris distefano yannis pappa rio...   0  \n",
       "1  curiosity daily westwood one education awardwi...   1  \n",
       "2  spirit multitude history boozy mythology legen...   2  \n",
       "3  soundtrack show iheartradio tv film soundtrack...   3  \n",
       "4  writing excuse brandon sanderson mary kowal da...   4  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcasts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Recommendation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_title_from_index(index):\n",
    "    return podcasts_df[podcasts_df.ID == index][\"title\"].values[0]\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    return podcasts_df[podcasts_df.title == title][\"ID\"].values[0]\n",
    "\n",
    "def get_recommendations(podcast_id, sim_matrix):\n",
    "    recommendations = list()\n",
    "    \n",
    "    podcast_title = get_title_from_index(podcast_id)\n",
    "    similar_podcasts =  list(enumerate(sim_matrix[podcast_id]))\n",
    "    sorted_similar_podcast = sorted(similar_podcasts,key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    for i in range(11):\n",
    "        title = get_title_from_index(sorted_similar_podcast[i][0])\n",
    "        recommendations.append(title)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "test_podcasts = ['The Daily', 'Up First', 'VIEWS with David Dobrik and Jason Nash', 'Impaulsive with Logan Paul',\n",
    "                 'The Bill Simmons Podcast', 'My Favorite Murder with Karen Kilgariff and Georgia Hardstark',\n",
    "                 'This American Life', 'Joel Osteen Podcast', 'TED Radio Hour', 'Call Her Daddy', \n",
    "                 'Skip and Shannon: Undisputed'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity + CountVectorizer (Bag of Words) Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(podcasts_df[\"text\"])\n",
    "cv_cosine_sim = cosine_similarity(cv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Daily', 'Impeachment Inquiry: Updates from The Washington Post', 'Impeachment: A Daily Podcast', 'The Takeaway', 'Article II: Inside Impeachment', \"The Daily 202's Big Idea\", 'The 11th Hour with Brian Williams', 'Bill O’Reilly’s No Spin News and Analysis', 'The Last Word with Lawrence O’Donnell', 'Up First', 'Impeachment Today']\n",
      "\n",
      "['Up First', 'Impeachment: A Daily Podcast', 'Impeachment Inquiry: Updates from The Washington Post', 'The Daily', 'Article II: Inside Impeachment', 'The 11th Hour with Brian Williams', 'Bill O’Reilly’s No Spin News and Analysis', \"The Daily 202's Big Idea\", 'The Takeaway', 'Can He Do That?', 'The Last Word with Lawrence O’Donnell']\n",
      "\n",
      "['VIEWS with David Dobrik and Jason Nash', 'Instant Message', 'I Am In Eskew', 'Jalen & Jacoby', 'The Axe Files with David Axelrod', 'Getting Things Done', 'The Tower', 'The Permaculture Podcast', 'Making It With Jimmy Diresta, Bob Clagett and David Picciuto', 'Psychology of Eating', 'Blank Check with Griffin & David']\n",
      "\n",
      "['Impaulsive with Logan Paul', 'Sexology', 'BEHIND THE SCENES', 'MOONFACE', 'The Tom Woods Show', 'The Flop House', 'The Long Run with Luke Timmerman', 'Heartland Radio 2.0', 'Another Kingdom', 'Curious with Josh Peck', 'Just Roll With It - A Dungeons and Dragons Podcast']\n",
      "\n",
      "['The Bill Simmons Podcast', 'The Rewatchables', 'Book of Basketball 2.0', 'Real Time with Bill Maher', 'The Ringer NFL Show', 'NFL: The Dave Dameshek Football Program', 'Monday Morning Podcast', 'Chris Simms Unbuttoned', 'The Ryen Russillo Podcast', 'The Bill Bert Podcast', 'The GM Shuffle with Michael Lombardi and Adnan Virk']\n",
      "\n",
      "['My Favorite Murder with Karen Kilgariff and Georgia Hardstark', \"Don't Talk to Strangers\", 'Murder Minute', 'Wine & Crime', 'Fresh Hell Podcast', 'Unsolved Murders: True Crime Stories', 'Murder, Myth & Mystery', 'Criminology', 'Jensen and Holes: The Murder Squad', 'Murder, etc.', 'Murder In The Rain']\n",
      "\n",
      "['This American Life', 'History of Japan', 'ED MYLETT SHOW', 'The Toxic People Detox | Self-Care & Difficult People Survival Strategies', 'Meaningful Conversations with Maria Shriver', 'This is the Gospel Podcast', 'The Hidden People', 'Locked Up Abroad', 'For The Love With Jen Hatmaker Podcast', 'The Incomparable Radio Theater', 'The Stacking Benjamins Show']\n",
      "\n",
      "['Joel Osteen Podcast', 'Joel Osteen Podcast', 'Saddleback Church Weekend Messages', 'Daily Grace', 'Marriage After God', 'Love Worth Finding on Oneplace.com', 'All Things Catholic with Dr. Edward Sri', 'Bethel Church Sermon of the Week', 'The Porch', 'Rush: Holy Spirit in Modern Life | A Practical & Prophetic Podcast for Men and Women', \"Don't Mom Alone Podcast\"]\n",
      "\n",
      "['TED Radio Hour', 'The Metaphysical Hour hosted by Julia Cannon', 'TED Talks Art', 'TED Talks Business', 'CarProUSA Radio Show', 'TED Talks Science and Medicine', 'The TED Interview', 'Freakonomics Radio', 'The Creeping Hour', 'TED Talks Society and Culture', 'Zero Hours']\n",
      "\n",
      "['Call Her Daddy', 'Stiff Socks', 'Two Judgey Girls', 'NAKED with Catt Sadler', 'Becoming Something with Jonathan Pokluda', 'Slay Girl Slay', 'Hot Marriage. Cool Parents.', 'Safe For Work', 'The Walynn Collins Show', 'Coffee Convos Podcast with Kail Lowry & Lindsie Chrisley', 'Girl Were You Alone? An *NSYNC Podcast']\n",
      "\n",
      "['Skip and Shannon: Undisputed', 'First Things First', 'Golic and Wingo', 'Speak For Yourself with Whitlock & Wiley', 'The Herd with Colin Cowherd', 'The Odd Couple with Chris Broussard & Rob Parker', 'The Michael Kay Show', 'Joe Benigno and Evan Roberts', 'Pick Six NFL Podcast', 'Pardon My Take', 'The Ringer NFL Show']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_podcasts:\n",
    "    print(get_recommendations(get_index_from_title(i), cv_cosine_sim))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "tf_matrix = tf.fit_transform(podcasts_df[\"text\"])\n",
    "tf_cosine_sim = cosine_similarity(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Daily', 'Impeachment Inquiry: Updates from The Washington Post', \"The Daily 202's Big Idea\", 'The 11th Hour with Brian Williams', 'Article II: Inside Impeachment', 'Impeachment: A Daily Podcast', 'The Takeaway', 'The Last Word with Lawrence O’Donnell', 'Bill O’Reilly’s No Spin News and Analysis', 'The Situation Room with Wolf Blitzer', 'The Rachel Maddow Show']\n",
      "\n",
      "['Up First', 'Impeachment Inquiry: Updates from The Washington Post', 'The Daily', 'Article II: Inside Impeachment', 'The 11th Hour with Brian Williams', 'Impeachment: A Daily Podcast', \"The Daily 202's Big Idea\", 'Can He Do That?', 'The Last Word with Lawrence O’Donnell', 'Bill O’Reilly’s No Spin News and Analysis', 'The Takeaway']\n",
      "\n",
      "['VIEWS with David Dobrik and Jason Nash', 'Instant Message', 'How Did This Get Made?', 'Light The Fight- Parenting Podcast', 'Flow Sessions with Jason Silva', 'This Week in Startups - Audio', 'The Tower', 'True Cold Case Files with Jason and Daisy', 'Horror Hill: A Horror Anthology and Scary Stories Series Podcast', 'Kids Bible Stories', 'Psychology of Eating']\n",
      "\n",
      "['Impaulsive with Logan Paul', 'MOONFACE', 'The Tom Woods Show', 'Sexology', 'The Tim Dillon Show', 'The Long Run with Luke Timmerman', 'Ripper Magoos with Bob Menery', 'Come Follow Me Daily', 'The Flop House', 'Sex Talk With My Mom', 'Below the Belt']\n",
      "\n",
      "['The Bill Simmons Podcast', 'The Rewatchables', 'Book of Basketball 2.0', 'Headlong: Missing Richard Simmons', 'The Ringer NFL Show', 'Real Time with Bill Maher', 'Chris Simms Unbuttoned', 'Speak For Yourself with Whitlock & Wiley', 'The Pat McAfee Show 2.0', 'NFL: The Dave Dameshek Football Program', 'The GM Shuffle with Michael Lombardi and Adnan Virk']\n",
      "\n",
      "['My Favorite Murder with Karen Kilgariff and Georgia Hardstark', 'Do You Need A Ride?', 'Wire Talk with Karen Stubbs', 'The Murder In My Family', 'Murder Minute', 'The Walking Dead ‘Cast', 'Murderous Minors: killer kids', \"Don't Talk to Strangers\", 'Murder, Myth & Mystery', 'Jensen and Holes: The Murder Squad', 'Criminology']\n",
      "\n",
      "['This American Life', 'Experimental Brewing', '1A', 'Through the Looking Glass: A LOST Retrospective', 'BeerSmith Home and Beer Brewing Podcast', 'Talking Beat - from the Portland Police Bureau', 'Haunted Hell House of Horror', 'The Grave Talks | Haunted, Paranormal & Supernatural', 'Sinisterhood', 'Slow Burn', 'Haunted Places']\n",
      "\n",
      "['Joel Osteen Podcast', 'Joel Osteen Podcast', 'Joyce Meyer Ministries TV Podcast', 'Joyce Meyer Enjoying Everyday Life® TV Audio Podcast', 'Marriage After God', 'Daily Grace', 'Fresh Life Church', 'Brilliant Perspectives', 'Bethel Church Sermon of the Week', 'Saddleback Church Weekend Messages', 'Pastor Robert Morris Ministries on Oneplace.com']\n",
      "\n",
      "['TED Radio Hour', 'The TED Interview', 'TED Talks Art', 'TED Talks Science and Medicine', 'TED Talks Business', \"Hunted: Inside Ted Bundy's Trail of Terror\", 'TED Talks Society and Culture', 'TED Talks Education', 'TED Talks Daily (HD video)', 'TED Talks Daily (SD video)', 'TED Talks Music']\n",
      "\n",
      "['Call Her Daddy', 'hey, girl.', 'Becoming Something with Jonathan Pokluda', 'Fierce Girls', 'Stiff Socks', 'Girls Night with Stephanie May Wilson', 'Grammar Girl Quick and Dirty Tips for Better Writing', 'Two Judgey Girls', 'The Clever Girls Know Podcast', 'Quarter Life Crisis', 'Slay Girl Slay']\n",
      "\n",
      "['Skip and Shannon: Undisputed', 'First Things First', 'Golic and Wingo', 'Speak For Yourself with Whitlock & Wiley', 'The Herd with Colin Cowherd', 'The Odd Couple with Chris Broussard & Rob Parker', 'Pick Six NFL Podcast', 'First Take', 'Pardon My Take', 'Chris Simms Unbuttoned', 'Pro Football Talk Live with Mike Florio']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_podcasts:\n",
    "    print(get_recommendations(get_index_from_title(i), tf_cosine_sim))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity + Custom Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for document in X:\n",
    "            tokenized_doc = []\n",
    "            for sent in nltk.sent_tokenize(document):\n",
    "                tokenized_doc += nltk.word_tokenize(sent)\n",
    "            transformed_X.append(np.array(tokenized_doc))\n",
    "        return np.array(transformed_X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.wv.syn0[0])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = MyTokenizer().fit_transform(X)\n",
    "        \n",
    "        return np.array([\n",
    "            np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = list(podcasts_df.text)\n",
    "tokenized_text = [tokenizer.tokenize(i) for i in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "mean_embedding_vectorizer = MeanEmbeddingVectorizer(w2v_model)\n",
    "mean_embedded = mean_embedding_vectorizer.fit_transform(podcasts_df['text'])\n",
    "w2v_cosine_sim = cosine_similarity(mean_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Daily', 'Impeachment: A Daily Podcast', 'Can He Do That?', 'Up First', 'The Takeaway', 'Global News Podcast', 'Talking Feds', 'Skimm This', \"LRC Presents: All the President's Lawyers\", 'Bill O’Reilly’s No Spin News and Analysis', 'PBS NewsHour - Full Show']\n",
      "\n",
      "['Up First', 'The Daily', 'Impeachment: A Daily Podcast', 'Can He Do That?', 'Bill O’Reilly’s No Spin News and Analysis', 'PBS NewsHour - Full Show', 'Global News Podcast', \"LRC Presents: All the President's Lawyers\", 'PBS NewsHour - Segments', 'Talking Feds', 'Skimm This']\n",
      "\n",
      "['VIEWS with David Dobrik and Jason Nash', 'The Fighter & The Kid', 'Conan O’Brien Needs A Friend', 'The CONAN Podcast', 'Straight Up with Stassi', \"So Bad It's Good with Ryan Bailey\", 'Did I Stutter?? with Drew Lynch', 'Ripper Magoos with Bob Menery', 'Amy Schumer Presents: 3 Girls, 1 Keith', 'Adulting', 'You Up with Nikki Glaser']\n",
      "\n",
      "['Impaulsive with Logan Paul', 'To L And Back: An L Word Podcast', 'Comments by Celebs', 'The Basement Yard', 'Ghost Stories: A Podcast By Hinge', 'Not Skinny But Not Fat', 'The Archers', 'Berning In Hell', 'The MeatEater Podcast', 'Drew and Mike Show', 'Heartland Radio 2.0']\n",
      "\n",
      "['The Bill Simmons Podcast', 'The Peter King Podcast', 'The 49ers Insider Podcast', 'The Ryen Russillo Podcast', 'Skip and Shannon: Undisputed', 'Cleveland Browns Daily & More', 'The Odd Couple with Chris Broussard & Rob Parker', 'First Take', 'Minnesota Vikings Podcast Network', 'ESPN Podcasts', 'High Noon']\n",
      "\n",
      "['My Favorite Murder with Karen Kilgariff and Georgia Hardstark', 'Murder, Myth & Mystery', 'Wine & Crime', 'Cult Liter with Spencer Henry', \"Let's Taco 'Bout True Crime\", 'Down These Mean Streets (Old Time Radio Detectives)', 'Last Podcast On The Left', 'Fresh Hell Podcast', 'Jensen and Holes: The Murder Squad', 'Murderous Minors: killer kids', \"Don't Talk to Strangers\"]\n",
      "\n",
      "['This American Life', 'The Incomparable Radio Theater', 'Radio Diaries', 'The British History Podcast', 'Locked Up Abroad', 'American Presidents: Totalus Rankium', 'Headlong: Running from COPS', 'My Brother, My Brother And Me', 'Brought to you by...', 'Without Fail', 'The Uncertain Hour']\n",
      "\n",
      "['Joel Osteen Podcast', 'Joel Osteen Podcast', 'Saddleback Church Weekend Messages', 'Daily Grace', 'Encounter', 'The Porch', 'VOUS Church', 'The Fr. Mike Schmitz Catholic Podcast', 'Made For This with Jennie Allen', 'The Catholic Feminist', 'Passion City Church Podcast']\n",
      "\n",
      "['TED Radio Hour', 'Finding Mastery', 'That Made All the Difference', 'Defender Radio: The Podcast for Wildlife Advocates and Animal Lovers', 'WGRL NYC', 'EconTalk', 'The Kevin Rose Show', 'PT Pintcast - Physical Therapy', 'WildFed Podcast', 'Work in Progress with Sophia Bush', 'The Skinny Confidential Him & Her Podcast']\n",
      "\n",
      "['Call Her Daddy', 'Stiff Socks', 'Zane and Heath: Unfiltered', 'Coffee Convos Podcast with Kail Lowry & Lindsie Chrisley', 'Dead Ass with Khadeen and Devale Ellis', 'Woman Evolve with Sarah Jakes Roberts', 'Schnitt Talk', 'The Dirtbag Diaries', 'Bully and the Beast', 'Pretty Basic with Alisha Marie and Remi Cruz', 'Becoming Something with Jonathan Pokluda']\n",
      "\n",
      "['Skip and Shannon: Undisputed', 'First Things First', 'First Take', 'The Bill Simmons Podcast', 'Jalen & Jacoby', 'Golic and Wingo', 'The Odd Couple with Chris Broussard & Rob Parker', 'PTI', 'Below the Belt', 'Around the NFL', 'Speak For Yourself with Whitlock & Wiley']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_podcasts:\n",
    "    print(get_recommendations(get_index_from_title(i), w2v_cosine_sim))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity + GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format(\"../word2vec/glove.6B.50d.txt.word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/Users/sidd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "/Users/sidd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "glove_mean_embedding_vectorizer = MeanEmbeddingVectorizer(glove_model)\n",
    "glove_mean_embedded = glove_mean_embedding_vectorizer.fit_transform(podcasts_df['text'])\n",
    "glove_cosine_sim = cosine_similarity(glove_mean_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Daily', 'Up First', 'Impeachment: A Daily Podcast', 'The Lawfare Podcast', 'Bag Man', 'Can He Do That?', 'CBS This Morning', 'Impeachment Inquiry: Updates from The Washington Post', 'All In with Chris Hayes', 'The Takeaway', 'The New Yorker: Politics and More']\n",
      "\n",
      "['Up First', 'The Daily', 'The Lawfare Podcast', 'Impeachment: A Daily Podcast', 'Bag Man', 'What Next | Daily News and Analysis', 'Impeachment Inquiry: Updates from The Washington Post', 'The Situation Room with Wolf Blitzer', 'PBS NewsHour - Segments', 'All In with Chris Hayes', 'The Lead with Jake Tapper']\n",
      "\n",
      "['VIEWS with David Dobrik and Jason Nash', 'Help! I Suck at Dating with Dean, Vanessa and Jared', 'Amy Schumer Presents: 3 Girls, 1 Keith', 'Dead Pilots Society', \"So Bad It's Good with Ryan Bailey\", 'The Ben and Ashley I Almost Famous Podcast', 'Out in the Wild', 'Your 2 Dads w/ Sean & Julian', 'Good Morning From Hell', 'The Bobby Bones Show', 'Scrubbing In with Becca Tilley & Tanya Rad']\n",
      "\n",
      "['Impaulsive with Logan Paul', 'The Kirk Minihane Show', 'Reality Steve Podcast', 'Hollywood Unlocked [UNCENSORED]', 'Two Judgey Girls', 'The HoneyDew with Ryan Sickler', 'The Last Laugh: A Daily Beast Podcast', 'The Adam and Dr. Drew Show', 'QAnon Anonymous', 'Hot Marriage. Cool Parents.', 'The Candace Owens Show']\n",
      "\n",
      "['The Bill Simmons Podcast', 'The Peter King Podcast', 'First Things First', 'ESPN Podcasts', 'NFL: Move the Sticks with Daniel Jeremiah & Bucky Brooks', 'Cleveland Browns Daily & More', 'Joe Benigno and Evan Roberts', 'Book of Basketball 2.0', 'Chris Simms Unbuttoned', 'Footballguys.com - The Audible - Fantasy Football Info for Serious Fans', 'The Herd with Colin Cowherd']\n",
      "\n",
      "['My Favorite Murder with Karen Kilgariff and Georgia Hardstark', 'Murderous Minors: killer kids', 'You Must Remember Manson', '...These Are Their Stories: The Law & Order Podcast', 'Fresh Hell Podcast', \"Let's Taco 'Bout True Crime\", 'Hollywood & Crime', 'Atlanta Monster', 'Red Scare', 'Reality Life with Kate Casey', 'Once Upon A Crime | True Crime']\n",
      "\n",
      "['This American Life', 'UK True Crime Podcast', 'A Waste Of Time with ItsTheReal', \"Heaven's Gate\", 'Locked Up Abroad', 'The David Banner Podcast', 'The Brooklyn Blast Furnace', 'The Incomparable Radio Theater', 'Astonishing Legends', 'Outside Podcast', 'Upzoned']\n",
      "\n",
      "['Joel Osteen Podcast', 'Joel Osteen Podcast', 'North Point Community Church', 'VOUS Church', 'Pathway to Victory on Oneplace.com', 'Passion City Church Podcast', 'The Fr. Mike Schmitz Catholic Podcast', 'As For Me And My House', '4:13 Podcast', 'All In', 'Daily Grace']\n",
      "\n",
      "['TED Radio Hour', 'Under The Skin with Russell Brand', 'Creative Processing with Joseph Gordon-Levitt', 'Love Your Voice with Roger Love', 'The Ezra Klein Show', 'The Kevin Rose Show', 'Ten Percent Happier with Dan Harris', 'Conversations with Tyler', 'Being Well with Dr. Rick Hanson', 'Freakonomics Radio', 'The Enneagram Journey']\n",
      "\n",
      "['Call Her Daddy', 'A Date With Dateline', \"Couldn't Help But Wonder: A Sex and the City Podcast with Jamie Lee and Rose Surnow\", 'Derek Sivers', \"The On-Call Room: A Grey's Anatomy Podcast\", 'Get Off My Lawn Podcast w/ Gavin McInnes', 'The Papaya Podcast', 'The Podfathers', 'DELETE THIS', 'Crime in Sports', 'Take it or Leave it']\n",
      "\n",
      "['Skip and Shannon: Undisputed', 'First Things First', 'Golic and Wingo', 'Speak For Yourself with Whitlock & Wiley', 'Joe Benigno and Evan Roberts', 'The Odd Couple with Chris Broussard & Rob Parker', 'Scal and Pals', 'The Lowe Post', 'The Herd with Colin Cowherd', 'The Bill Simmons Podcast', 'Jalen & Jacoby']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_podcasts:\n",
    "    print(get_recommendations(get_index_from_title(i), glove_cosine_sim))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity + Word2Vec + Smooth Inverse Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_principal_component(X):\n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
    "    svd.fit(X)\n",
    "    pc = svd.components_\n",
    "    XX = X - X.dot(pc.transpose()) * pc\n",
    "    return XX\n",
    "\n",
    "def smooth_inverse_frequency(sent, a=0.001, word2vec_model=w2v_model):\n",
    "    word_counter = {}\n",
    "    sentences = []\n",
    "    total_count = 0\n",
    "    no_of_sentences = 0\n",
    "    \n",
    "    for s in sent:\n",
    "        for w in s:\n",
    "            if w in word_counter:\n",
    "                word_counter[w] = word_counter[w] + 1\n",
    "            else:\n",
    "                word_counter[w] = 1\n",
    "        total_count = total_count + len(s)\n",
    "        no_of_sentences = no_of_sentences + 1\n",
    "    \n",
    "    sents_emd = []\n",
    "    for s in sent:\n",
    "        sent_emd = []\n",
    "        for word in s:\n",
    "            if word in word2vec_model:\n",
    "                emd = (a/(a + (word_counter[word]/total_count)))*word2vec_model[word]\n",
    "                sent_emd.append(emd)\n",
    "        sum_ = np.array(sent_emd).sum(axis=0)\n",
    "        sentence_emd = sum_/float(no_of_sentences)\n",
    "        sents_emd.append(sentence_emd)\n",
    "        \n",
    "    new_sents_emb = remove_first_principal_component(np.array(sents_emd))\n",
    "    return new_sents_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/Users/sidd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "sif_text_emd = smooth_inverse_frequency(text_list)\n",
    "sif_cosine_sim = cosine_similarity(sif_text_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Daily', 'Impeachment Inquiry: Updates from The Washington Post', 'Criminal', 'Queens Podcast', 'Omnarchy', 'La Corneta', 'EEs Talk Tech - An Electrical Engineering Podcast', 'The Quilting Company Podcast', 'Constitutional', 'The Drum Show', 'Quantum Physics I']\n",
      "\n",
      "['Up First', 'The Paul Tripp Podcast', 'Best of Both Worlds Podcast', 'The General Hospital Podcast', \"Heaven's Gate\", 'Wild Thing', 'Post Reports', 'Stay Tuned with Preet', 'Article II: Inside Impeachment', \"Quentin Tarantino's Feature Presentation\", 'The Chris Hogan Show']\n",
      "\n",
      "['VIEWS with David Dobrik and Jason Nash', 'The Bunker', 'Beach Too Sandy, Water Too Wet', 'Solid Joys Daily Devotional', 'Bald Move TV', \"WHOA That's Good Podcast\", 'MarriageToday Audio Podcast', 'Survivor: Island of the Idols - Recaps from Rob has a Podcast | RHAP', 'FieldCraft Survival', 'KEXP Presents Music That Matters', 'Instant Message']\n",
      "\n",
      "['Impaulsive with Logan Paul', 'The Tom Ferry Podcast Experience', 'Purchasing Truth', 'Yogaland Podcast', 'Science Friday Videos', 'Team Never Quit', 'American Hauntings Podcast', 'The GaryVee Audio Experience', 'The Real Estate Guys Radio Show - Real Estate Investing Education for Effective Action', \"Paul van Dyk's VONYC Sessions Podcast\", 'She Makes Money Moves']\n",
      "\n",
      "['The Bill Simmons Podcast', 'The Guilty Feminist', 'The Mindset Mentor', 'Hang Up and Listen', 'Hallmark Channels’ Bubbly Sesh', 'Something Was Wrong', 'The Giant Beastcast', 'The Daily Beans', 'The Homer Alaska Podcast', 'Not Skinny But Not Fat', 'How to Be Awesome at Your Job']\n",
      "\n",
      "['My Favorite Murder with Karen Kilgariff and Georgia Hardstark', 'Sports Gambling Podcast', 'God Awful Movies', 'The Lefkoe Show', 'Simple', 'The Dave Portnoy Show', 'Simple Families Podcast | Parenting + Minimalism', 'You Up with Nikki Glaser', 'For Crying Out Loud', '#DORK', 'The College Football Podcast With Herbie & Pollack']\n",
      "\n",
      "['This American Life', 'Spectacular Failures', 'ESPN FC', 'My Life of Crime with Erin Moriarty', 'The Ben Shapiro Show', 'World War II Tour - National Museum of the USAF', 'True Crime Fan Club Podcast', 'German Podcast', 'Cybernautica', 'Scared To Death', 'The Walking Dead ‘Cast']\n",
      "\n",
      "['Joel Osteen Podcast', 'Joel Osteen Podcast', \"After Midnight: Phish's Big Cypress Festival\", 'The Kevin Rose Show', 'Killer Instinct', 'The Last Movie', 'Start Today Morning Show', 'The Re-Solved Mysteries Podcast', 'MarriageToday Audio Podcast', \"WHOA That's Good Podcast\", 'The School of Greatness']\n",
      "\n",
      "['TED Radio Hour', 'The Breakdown with Shaun King', 'Strange Matters Podcast', 'The Trauma Therapist', \"Conversation & Pronunciation: Learn English with The Rachel's English Podcast\", 'Speaking of Sex with The Pleasure Mechanics', 'Emperors of Rome', 'Deep Energy 2.0 - Music for Sleep, Meditation, Relaxation, Massage and Yoga', '15 Minute History', 'Anxiety Slayer™ with Shann and Ananga', 'Tara Brach']\n",
      "\n",
      "['Call Her Daddy', 'Worldly', 'Fortnite world', 'Read-Aloud Revival', 'W&W Rave Culture Radio', 'Podcast Unlocked', 'Clapcast from Claptone', 'The Martin Garrix Show', 'Dance Club Podcast   -   DJ Toshi Tyler', 'Kinda Funny Games Daily', 'Armchair Expert with Dax Shepard']\n",
      "\n",
      "['Skip and Shannon: Undisputed', 'Still Processing', 'The Bechdel Cast', 'Crime in Sports', 'All The Smoke', 'This Had Oscar Buzz', 'Book Riot - The Podcast', 'Chicks in the Office', 'Face Jam', 'Dumb People Town', 'Blamo! | Exploring Fashion with the People Who Shape It']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_podcasts:\n",
    "    print(get_recommendations(get_index_from_title(i), sif_cosine_sim))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMD (Package Not Working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd\n",
    "from gensim.similarities import WmdSimilarity\n",
    "glove_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((len(text_list), len(text_list)))\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text_list)):\n",
    "    for j in range(len(text_list)):\n",
    "        if i == j:\n",
    "            continue  # self-distance is 0.0\n",
    "        if i > j:\n",
    "            D[i, j] = D[j, i]  # re-use earlier calc\n",
    "        D[i, j] = glove_model.wmdistance(text_list[i], text_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_principal_component(X):\n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
    "    svd.fit(X)\n",
    "    pc = svd.components_\n",
    "    XX = X - X.dot(pc.transpose()) * pc\n",
    "    return XX\n",
    "\n",
    "\n",
    "def run_sif_benchmark(sentences1, sentences2, model, freqs={}, use_stoplist=False, a=0.001):\n",
    "    total_freq = sum(freqs.values())\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    # SIF requires us to first collect all sentence embeddings and then perform\n",
    "    # common component analysis.\n",
    "    for (sent1, sent2) in zip(sentences1, sentences2):\n",
    "        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
    "        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
    "\n",
    "        tokens1 = [token for token in tokens1 if token in model]\n",
    "        tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "        weights1 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens1]\n",
    "        weights2 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens2]\n",
    "\n",
    "        embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
    "        embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
    "\n",
    "        embeddings.append(embedding1)\n",
    "        embeddings.append(embedding2)\n",
    "\n",
    "    embeddings = remove_first_principal_component(np.array(embeddings))\n",
    "    sims = [cosine_similarity(embeddings[idx * 2].reshape(1, -1),\n",
    "                              embeddings[idx * 2 + 1].reshape(1, -1))[0][0]\n",
    "            for idx in range(int(len(embeddings) / 2))]\n",
    "\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
